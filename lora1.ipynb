{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13407479,"sourceType":"datasetVersion","datasetId":8397441}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"eca31278-ed65-416e-af65-1283a6e4f521","cell_type":"code","source":"from enum import Enum\nfrom functools import partial\nimport pandas as pd\nimport torch\nimport json\nfrom transformers import BitsAndBytesConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\nfrom datasets import load_dataset\nimport os\nfrom trl import SFTConfig, SFTTrainer\nfrom peft import LoraConfig, TaskType   \nos.environ['HF_TOKEN']=\"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\"\n# \"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\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-18T11:25:42.930765Z","iopub.execute_input":"2025-10-18T11:25:42.931396Z","iopub.status.idle":"2025-10-18T11:26:12.136303Z","shell.execute_reply.started":"2025-10-18T11:25:42.931369Z","shell.execute_reply":"2025-10-18T11:26:12.135542Z"}},"outputs":[{"name":"stderr","text":"2025-10-18 11:25:55.077628: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760786755.272577      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760786755.328726      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"id":"0bcd5d07","cell_type":"code","source":"\n\nseed = 42\nset_seed(seed)\n\n\n\nmodel_name = \"facebook/MobileLLM-Pro\"\ntokenizer = AutoTokenizer.from_pretrained(model_name,subfolder=\"base\")\n\n\ndataset = load_dataset('json', data_files='/kaggle/input/ddddddd/discourse_qa.json')\ndataset = dataset.remove_columns([\"question\", \"answer\"])\n\ndataset = dataset[\"train\"].train_test_split(0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-18T11:28:30.674206Z","iopub.execute_input":"2025-10-18T11:28:30.674797Z","iopub.status.idle":"2025-10-18T11:28:39.488641Z","shell.execute_reply.started":"2025-10-18T11:28:30.674773Z","shell.execute_reply":"2025-10-18T11:28:39.488043Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/237k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecb17012e05a47f7ab510e6fe74993d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"base/tokenizer.json:   0%|          | 0.00/27.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73a4077ec8994ae889df93df16e83cb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"base/tokenizer.model:   0%|          | 0.00/3.62M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f010afa5503d4cfca624a459e338f9b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/106 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"408d30cb266f4f49aeae0e1855b81496"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cebd6cbfb2441d0ab4861e2e0be825c"}},"metadata":{}}],"execution_count":5},{"id":"00bdda66","cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_name,\n                                             attn_implementation='eager',\n                                             device_map=\"cuda\",dtype=torch.bfloat16,subfolder=\"base\")\nmodel.config.use_cache = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-18T11:28:43.595884Z","iopub.execute_input":"2025-10-18T11:28:43.596184Z","iopub.status.idle":"2025-10-18T11:28:59.569453Z","shell.execute_reply.started":"2025-10-18T11:28:43.596163Z","shell.execute_reply":"2025-10-18T11:28:59.568648Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d30fcf4d30ad4e9dbd420a8a1beb3fa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"base/model.safetensors:   0%|          | 0.00/2.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf278c5507f243a49447920e42e8c9d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/240 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"370f723a0ad94f3e81ff0062b43e202a"}},"metadata":{}}],"execution_count":6},{"id":"5b049b82","cell_type":"code","source":"rank_dimension = 4\nlora_alpha = 32\nlora_dropout = 0.1\n\npeft_config = LoraConfig(r=rank_dimension,\n                         lora_alpha=lora_alpha,\n                         lora_dropout=lora_dropout,\n                         target_modules=[\n                             \"q_proj\", \"k_proj\", \"v_proj\",\n                             \"o_proj\", \"gate_proj\", \"up_proj\",\n                             \"down_proj\"\n                             ],\n                         task_type=TaskType.CAUSAL_LM)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-18T11:29:42.893875Z","iopub.execute_input":"2025-10-18T11:29:42.894539Z","iopub.status.idle":"2025-10-18T11:29:42.899025Z","shell.execute_reply.started":"2025-10-18T11:29:42.894483Z","shell.execute_reply":"2025-10-18T11:29:42.898187Z"}},"outputs":[],"execution_count":8},{"id":"2d9180a5","cell_type":"code","source":"per_device_train_batch_size = 4\nper_device_eval_batch_size = 4\ngradient_accumulation_steps = 4\nlearning_rate = 1e-4\n\nnum_train_epochs=15\nwarmup_ratio = 0.1\nlr_scheduler_type = \"cosine\"\ntraining_arguments = SFTConfig(\n    # output_dir=output_dir,\n    # hub_private_repo=False,\n    # push_to_hub=True,\n\n\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    per_device_eval_batch_size=per_device_eval_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    save_strategy=\"no\",\n    eval_strategy=\"epoch\",\n    # logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    # max_grad_norm=max_grad_norm,\n    weight_decay=0.1,\n    warmup_ratio=warmup_ratio,\n    lr_scheduler_type=lr_scheduler_type,\n    report_to=\"tensorboard\",\n    bf16=True,\n    gradient_checkpointing=True,\n    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n    packing=False,\n    # max_length=None,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-18T11:29:45.892257Z","iopub.execute_input":"2025-10-18T11:29:45.892894Z","iopub.status.idle":"2025-10-18T11:29:45.926411Z","shell.execute_reply.started":"2025-10-18T11:29:45.892868Z","shell.execute_reply":"2025-10-18T11:29:45.925834Z"}},"outputs":[],"execution_count":9},{"id":"37bc1428","cell_type":"code","source":"torch.cuda.empty_cache()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T20:24:54.375307Z","iopub.execute_input":"2025-10-16T20:24:54.375533Z","iopub.status.idle":"2025-10-16T20:24:55.468645Z","shell.execute_reply.started":"2025-10-16T20:24:54.375517Z","shell.execute_reply":"2025-10-16T20:24:55.467643Z"}},"outputs":[],"execution_count":7},{"id":"b64cfd47","cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    processing_class=tokenizer,\n    peft_config=peft_config,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-18T11:29:50.310704Z","iopub.execute_input":"2025-10-18T11:29:50.311162Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Adding EOS to train dataset:   0%|          | 0/7950 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7527a560c1c4b87b1578d075e4a5e50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/7950 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad7cb269f9b40bb8040e3dbd4655939"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/7950 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13927f808e5c4eecb3a67406d5f1ccd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding EOS to eval dataset:   0%|          | 0/884 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d924f1e5e2c74dedb78779b9ec6729f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/884 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ca30adb8a04f75a27288f43d4809e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating eval dataset:   0%|          | 0/884 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b0812deeeab47e386ff3c9474ba1a17"}},"metadata":{}},{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 200008}.\n","output_type":"stream"}],"execution_count":null},{"id":"19291d8d","cell_type":"code","source":"# Usar el modelo fusionado para predecir la respuesta al prompt de antes\nfrom transformers import AutoTokenizer\nmodelo_unico = trainer.model.merge_and_unload()\n\ninput_text = \"\"\"### Instruction:\\nRespond as a patient with schizophrenia to the psychologist:\\n\\n### Input:can you tell me a bit about yourself .\\n\\n### Expected Response:\"\"\"\n\ninputs = tokenizer(input_text, return_tensors=\"pt\").to(modelo_unico.device)\nwith torch.no_grad():\n    outputs = modelo_unico.generate(\n        **inputs,\n        max_new_tokens=100,\n        do_sample=True,\n        # temperature=0.2,\n        # top_p=0.90,\n        pad_token_id=tokenizer.eos_token_id\n    )\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response[len(input_text):].strip())","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<start>a little bit. yeah. kinda of a student. &-um here's the story so. so I'm basically like maybe I'm like a super student so I can probably fit into some real good social lives. and I'm kinda interested in how I feel related to <you> or <you> and I'm kind of sure that what kind of me are. I'm a bit like kinda of the kind of a nerd on the part of you really like to kind\n"]}],"execution_count":22},{"id":"d2b9cfb0","cell_type":"code","source":"# Fusionar LoRA con el modelo base y subir el modelo único a Hugging Face Hub en un nuevo directorio\nmodelo_unico = trainer.model.merge_and_unload()\nmodelo_unico.push_to_hub(\"PabloCano1/llama1b-entreno\")\ntokenizer.push_to_hub(\"PabloCano1/llama1b-entreno\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:02:12.526050Z","iopub.execute_input":"2025-10-17T04:02:12.526311Z","iopub.status.idle":"2025-10-17T04:02:56.518314Z","shell.execute_reply.started":"2025-10-17T04:02:12.526287Z","shell.execute_reply":"2025-10-17T04:02:56.517428Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f648ae587da3452ebbaaa27089e2f180"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f95201187204579a7803180fb6d2c33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34962c1cdde04506be576d9e0567f855"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fac5c7e7ee95472a98651c85dddb2f30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39752f7da3314c2088a2218d59cab0aa"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/PabloCano1/llama1b-entreno/commit/4020684bfaa78032f97ebd9bc2676e2f3abdd2bf', commit_message='Upload tokenizer', commit_description='', oid='4020684bfaa78032f97ebd9bc2676e2f3abdd2bf', pr_url=None, repo_url=RepoUrl('https://huggingface.co/PabloCano1/llama1b-entreno', endpoint='https://huggingface.co', repo_type='model', repo_id='PabloCano1/llama1b-entreno'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":9},{"id":"20ef74bb","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}